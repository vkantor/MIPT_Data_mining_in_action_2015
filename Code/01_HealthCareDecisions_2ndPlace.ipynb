{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexander Guschin, 2nd place in Countable Care: Modeling Women's Health Care Decisions\n",
    "\n",
    "http://www.drivendata.org/competitions/6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from __future__ import division\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/xgboost/wrapper/')\n",
    "import xgboost as xgb\n",
    "from multiprocessing import Pool\n",
    "import sklearn\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "def pool(func, arg, N=15):\n",
    "    mpool = Pool(N)\n",
    "    ans = mpool.map(func, arg)\n",
    "    mpool.terminate()\n",
    "    return ans\n",
    "\n",
    "def sigm(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = read_csv('data/train_values.csv',',',low_memory=False)\n",
    "test = read_csv('data/test_values.csv',',',low_memory=False)\n",
    "labels = read_csv('data/train_labels.csv',',')\n",
    "sampleSubmission = read_csv('data/SubmissionFormat.csv',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xcols = list(train.columns)\n",
    "xcols.remove('id')\n",
    "\n",
    "ycols = list(labels.columns)\n",
    "ycols.remove('id')\n",
    "\n",
    "for c in train.columns:\n",
    "    if train[c].unique().shape[0] == 1:\n",
    "        xcols.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_loss16(y_true, y_pred):\n",
    "    return log_loss(y_true, y_pred, eps = 1e-16)\n",
    "\n",
    "logloss16 = sklearn.metrics.make_scorer(log_loss16, needs_proba = True)\n",
    "\n",
    "def sort_grid_scores(grid_scores_):\n",
    "    order = [np.arange(len(grid_scores_))[np.argsort([i[1] for i in grid_scores_])]]\n",
    "    return np.array(gs.grid_scores_)[order]\n",
    "\n",
    "def print_grid_scores(grid_scorer):\n",
    "    \n",
    "    sorted_scores = sort_grid_scores(grid_scorer.grid_scores_)\n",
    "    \n",
    "    for params, mean_score, scores in sorted_scores:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() / 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "logging.info('')\n",
    "\n",
    "train2 = train.copy().fillna(-1)\n",
    "test2  = test.copy().fillna(-1)\n",
    "\n",
    "def le_preprocess(c):\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    le.fit(np.concatenate([train2[c].values,test2[c].values]))\n",
    "    train2[c] = le.transform(train2[c].values)\n",
    "    test2 [c] = le.transform(test2 [c].values)\n",
    "    \n",
    "    return train2[c], test2[c]\n",
    "\n",
    "lecols = ['release']\n",
    "for c in train2.columns:\n",
    "    if c[0] == 'c' : lecols += [c]\n",
    "\n",
    "pool = Pool(15)\n",
    "transformed_columns = pool.map(le_preprocess, lecols)\n",
    "pool.terminate()\n",
    "\n",
    "for i,c in enumerate(lecols):\n",
    "    train2[c] = transformed_columns[i][0]\n",
    "    test2 [c] = transformed_columns[i][1]\n",
    "    \n",
    "logging.info('')\n",
    "\n",
    "train2.to_csv('data/train2.csv',index=False)\n",
    "test2.to_csv('data/test2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train2 = read_csv('data/train2.csv')\n",
    "test2  = read_csv('data/test2.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "logging.info('')\n",
    "v = DictVectorizer(sparse=False)\n",
    "D = [dict(row) for i,row in train[xcols].fillna(-1).iterrows()]\n",
    "trainV = v.fit_transform(D)\n",
    "logging.info('')\n",
    "D = [dict(row) for i,row in test[xcols].fillna(-1).iterrows()]\n",
    "testV = v.transform(D)\n",
    "logging.info('')\n",
    "print train.shape, trainV.shape, testV.shape\n",
    "\n",
    "df(trainV).to_csv('data/trainV.csv',index=False)\n",
    "df(testV).to_csv('data/testV.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainV = read_csv('data/trainV.csv')\n",
    "testV  = read_csv('data/testV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf_imp = []\n",
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=15, criterion='entropy', max_features=100)\n",
    "\n",
    "imp_cols = xcols[:]\n",
    "\n",
    "loss = []\n",
    "for i,c in enumerate(ycols):\n",
    "    rf.fit(train2[imp_cols], labels[c])\n",
    "    rf_imp += [rf.feature_importances_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_impV = []\n",
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=15, criterion='entropy', max_features=100)\n",
    "\n",
    "loss = []\n",
    "for i,c in enumerate(ycols):\n",
    "    rf.fit(trainV, labels[c])\n",
    "    rf_impV += [rf.feature_importances_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-features & Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(n_estimators=100, n_jobs=15, criterion='entropy', max_features=200)\n",
    "\n",
    "N = 5\n",
    "ytrain_N = np.zeros((train2.shape[0], 14, N))\n",
    "ycv_N = np.zeros((test2.shape[0], 14, N))\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    impcols = np.arange(trainV.shape[1])[rf_impV[nc] > 0.0001]    \n",
    "    \n",
    "    for i in range(N):\n",
    "        mask = train_test_split(np.arange(trainV.shape[0]), test_size=.5)\n",
    "        ansmask = []\n",
    "        for m1,m2 in [(mask[0],mask[1]), (mask[1],mask[0])]:\n",
    "            alg.fit(trainV[impcols].values[m1], labels[c].values[m1])\n",
    "            ytrain_N[m2,nc,i] = alg.predict_proba(trainV[impcols].values[m2])[:,1]\n",
    "            ansmask += [alg.predict_proba(testV[impcols].values)[:,1]]\n",
    "        ycv_N[:,nc,i] = sum(ansmask)/2\n",
    "    \n",
    "Mtrain = df(ytrain_N.mean(axis=2), columns=ycols)\n",
    "Mtest = df(ycv_N.mean(axis=2), columns=ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = RandomForestClassifier(n_estimators=100, n_jobs=15, criterion='entropy', max_features=300)\n",
    "\n",
    "N = 5\n",
    "ytrain_N = np.zeros((train2.shape[0], 14, N))\n",
    "ycv_N = np.zeros((test2.shape[0], 14, N))\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    impcols = np.arange(trainV.shape[1])[rf_impV[nc] > 0.00001]    \n",
    "    \n",
    "    for i in range(N):\n",
    "        mask = train_test_split(np.arange(trainV.shape[0]), test_size=.5)\n",
    "        ansmask = []\n",
    "        for m1,m2 in [(mask[0],mask[1]), (mask[1],mask[0])]:\n",
    "            alg.fit(trainV[impcols].values[m1], labels[c].values[m1])\n",
    "            ytrain_N[m2,nc,i] = alg.predict_proba(trainV[impcols].values[m2])[:,1]\n",
    "            ansmask += [alg.predict_proba(testV[impcols].values)[:,1]]\n",
    "        ycv_N[:,nc,i] = sum(ansmask)/2\n",
    "    \n",
    "Mtrain2 = df(ytrain_N.mean(axis=2), columns=ycols)\n",
    "Mtest2 = df(ycv_N.mean(axis=2), columns=ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fast(i):\n",
    "    random.seed(i)\n",
    "\n",
    "    mask = train_test_split(np.arange(train2.shape[0]), test_size=.5, random_state=i)\n",
    "    ansmask = []\n",
    "    ytrain_i = np.zeros(train2.shape[0])\n",
    "    for m1,m2 in [(mask[0],mask[1]), (mask[1],mask[0])]:\n",
    "        \n",
    "        alg.fit(trainV[impcols].values[m1], labels[c].values[m1])\n",
    "    \n",
    "        ytrain_i[m2] = sigm(alg.decision_function(trainV[impcols].values[m2]))\n",
    "        ansmask += [sigm(alg.decision_function(testV[impcols].values))]\n",
    "    return ytrain_i, sum(ansmask)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = sklearn.linear_model.LogisticRegression(C=0.01)\n",
    "\n",
    "N = 10\n",
    "ytrain_N = np.zeros((trainV.shape[0], 14))\n",
    "ycv_N = np.zeros((testV.shape[0], 14))\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    impcols = np.array(trainV.columns)[rf_impV[nc] > 0.0001]\n",
    "    \n",
    "    ans = pool(fast,range(N))\n",
    "    ytrain_N[:,nc] = sum([i[0] for i in ans]) / N\n",
    "    ycv_N[:,nc] = sum([i[1] for i in ans]) / N\n",
    "    \n",
    "MtrainLin = df(ytrain_N, columns=ycols)\n",
    "MtestLin = df(ycv_N, columns=ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = sklearn.svm.LinearSVC()\n",
    "\n",
    "N = 10\n",
    "ytrain_N = np.zeros((trainV.shape[0], 14))\n",
    "ycv_N = np.zeros((testV.shape[0], 14))\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    impcols = np.array(trainV.columns)[rf_impV[nc] > 0.0001]\n",
    "    \n",
    "    ans = pool(fast,range(N))\n",
    "    ytrain_N[:,nc] = sum([i[0] for i in ans]) / N\n",
    "    ycv_N[:,nc] = sum([i[1] for i in ans]) / N\n",
    "    \n",
    "MtrainLin2 = df(ytrain_N, columns=ycols)\n",
    "MtestLin2 = df(ycv_N, columns=ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = sklearn.linear_model.PassiveAggressiveClassifier()\n",
    "\n",
    "N = 10\n",
    "ytrain_N = np.zeros((trainV.shape[0], 14))\n",
    "ycv_N = np.zeros((testV.shape[0], 14))\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    impcols = np.array(trainV.columns)[rf_impV[nc] > 0.0001]\n",
    "    \n",
    "    ans = pool(fast,range(N))\n",
    "    ytrain_N[:,nc] = sum([i[0] for i in ans]) / N\n",
    "    ycv_N[:,nc] = sum([i[1] for i in ans]) / N\n",
    "    \n",
    "MtrainLin4 = df(ytrain_N, columns=ycols)\n",
    "MtestLin4 = df(ycv_N, columns=ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['scale_pos_weight'] = 1.0\n",
    "param['bst:eta'] = 0.25\n",
    "param['bst:max_depth'] = 5\n",
    "param['bst:colsample_bytree'] = 0.25\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 15\n",
    "\n",
    "num_round = 120\n",
    "plst = list(param.items())\n",
    "\n",
    "N = 5\n",
    "ytrain_N = np.zeros((trainV.shape[0], 14, N))\n",
    "ycv_N = np.zeros((testV.shape[0], 14, N))\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    impcols = np.arange(trainV.shape[1])[rf_impV[nc] > 0.0001]\n",
    "    \n",
    "    Gcv = xgb.DMatrix( testV.values, missing = -1 )\n",
    "    \n",
    "    for i in range(N):\n",
    "        mask = train_test_split(np.arange(trainV.shape[0]), test_size=.5)\n",
    "        m1, m2 = mask[0], mask[1]\n",
    "        \n",
    "        Gtrain1 = xgb.DMatrix( trainV.values[m1], label = labels[c].values[m1], missing = -1 )\n",
    "        Gtrain2 = xgb.DMatrix( trainV.values[m2], label = labels[c].values[m2], missing = -1 )\n",
    "        \n",
    "        ansmask = []\n",
    "        for t1,t2,m in [(Gtrain1, Gtrain2, m2), (Gtrain2, Gtrain1, m1)]:\n",
    "            \n",
    "            bst = xgb.train( plst, t1, num_round )#, watchlist )\n",
    "            ytrain_N[m,nc,i] = bst.predict( t2 )\n",
    "            ansmask += [bst.predict( Gcv )]        \n",
    "            \n",
    "        ycv_N[:,nc,i] = sum(ansmask)/2\n",
    "\n",
    "MtrainX = df(ytrain_N.mean(axis=2), columns=ycols)\n",
    "MtestX = df(ycv_N.mean(axis=2), columns=ycols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = sampleSubmission.copy()\n",
    "\n",
    "param = {}\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['scale_pos_weight'] = 1\n",
    "param['bst:eta'] = 0.2\n",
    "param['bst:max_depth'] = 2\n",
    "param['bst:colsample_bytree'] = 1\n",
    "param['bst:subsample'] = 1\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 15\n",
    "\n",
    "num_rounds = [105, 50, 50, 60, 65, 80, 40, 45, 45, 55, 35, 40, 40, 55]\n",
    "plst = list(param.items())\n",
    "\n",
    "for nc, c in enumerate(ycols):\n",
    "    Gtrain = xgb.DMatrix( np.concatenate([trainV, Mtrain, Mtrain2, MtrainLin, MtrainLin2, MtrainLin4, MtrainX], axis=1), label = labels[c].values, missing = -1 )\n",
    "    Gtest = xgb.DMatrix( np.concatenate([testV, Mtest, Mtest2, MtestLin, MtestLin2, MtestLin4, MtestX], axis=1), missing = -1 )\n",
    "\n",
    "    bst = xgb.train( plst, Gtrain, num_rounds[nc] )\n",
    "    pred = bst.predict( Gtest )\n",
    "    submission[c] = pred\n",
    "\n",
    "submission.to_csv('submissions/xgbFM.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theanets\n",
    "\n",
    "loss = []\n",
    "nn_predF = []\n",
    "for nc,c in enumerate(ycols):\n",
    "\n",
    "    ntrain = np.concatenate([Mtrain2, Mtrain, MtrainLin, MtrainLin2, MtrainLin4, MtrainX], axis=1).astype(np.float32)\n",
    "    ncv = np.concatenate([Mtest2, Mtest, MtestLin, MtestLin2, MtestLin4, MtestX], axis=1).astype(np.float32)\n",
    "    exp = theanets.Experiment(\n",
    "        theanets.Classifier,\n",
    "        layers=(6*14, 5, 2),\n",
    "        train_batches = 1000,\n",
    "    )\n",
    "\n",
    "    exp.train(\n",
    "        (ntrain, labels[c].values.astype(np.int32)),\n",
    "    )\n",
    "\n",
    "    pred = exp.network.predict(ncv)[:,1]\n",
    "    nn_predF += [pred]\n",
    "    \n",
    "submission = sampleSubmission.copy()\n",
    "\n",
    "for nc,c in enumerate(ycols):\n",
    "    submission[c] = nn_predF[nc]\n",
    "    \n",
    "submission.to_csv('submissions/nnM.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = sampleSubmission.copy()\n",
    "rf = ExtraTreesClassifier(n_estimators=1000, n_jobs=15, criterion='entropy', max_features=200)\n",
    "\n",
    "for nc,c in enumerate(ycols):\n",
    "    imp_cols = np.arange(trainV.shape[1])[rf_impV[nc] > 0.0001]\n",
    "    \n",
    "    rf.fit(trainV[imp_cols], labels[c])\n",
    "    pred = rf.predict_proba(testV[imp_cols])[:,1]\n",
    "         \n",
    "    submission[c] = pred\n",
    "    \n",
    "submission.to_csv('submissions/rfF.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = sampleSubmission.copy()\n",
    "\n",
    "param = {}\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['scale_pos_weight'] = 1.0\n",
    "param['bst:eta'] = 0.25\n",
    "param['bst:max_depth'] = 5\n",
    "param['bst:colsample_bytree'] = 0.25\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 15\n",
    "\n",
    "num_round = 120\n",
    "plst = list(param.items())\n",
    "\n",
    "xgb_predF = []\n",
    "\n",
    "loss = []\n",
    "for i,c in enumerate(ycols[:]):\n",
    "\n",
    "    Gtrain = xgb.DMatrix( trainV.values, label = labels[c].values, missing = -1 )\n",
    "    Gtest = xgb.DMatrix( testV.values, missing = -1 )\n",
    "    \n",
    "    bst = xgb.train( plst, Gtrain, num_round )\n",
    "    pred = bst.predict( Gtest )\n",
    "    \n",
    "    submission[c] = pred\n",
    "    \n",
    "submission.to_csv('submissions/xgbF.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info('')\n",
    "\n",
    "submission = sampleSubmission.copy()\n",
    "\n",
    "rf = ExtraTreesClassifier(n_estimators=200, n_jobs=15, criterion='entropy', max_features=320)\n",
    "\n",
    "for c in ycols:\n",
    "    impcols = np.arange(trainV.shape[1])[rf_impV[nc] > 0.0001]\n",
    "    rf.fit(np.concatenate([trainV[impcols], Mtrain, Mtrain2, MtrainLin, MtrainLin2, MtrainLin4, MtrainX], axis=1), labels[c])\n",
    "    pred = rf.predict_proba(np.concatenate([testV[impcols], Mtest, Mtest2, MtestLin, MtestLin2, MtestLin4, MtestX], axis=1))[:,1]\n",
    "\n",
    "    submission[c] = pred\n",
    "    \n",
    "submission.to_csv('submissions/rfFM.csv',index=False)\n",
    "\n",
    "logging.info('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1 = read_csv('submissions/nnM.csv')\n",
    "sub2 = read_csv('submissions/rfFM.csv')\n",
    "sub3 = read_csv('submissions/xgbFM.csv')\n",
    "sub4 = read_csv('submissions/rfF.csv')\n",
    "sub5 = read_csv('submissions/xgbF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissionMix = sampleSubmission.copy()\n",
    "\n",
    "for c in ycols:\n",
    "    pred = (sub1[c].values * 1/3 + sub2[c].values * 1/3 + sub3[c].values * 1/3) * .75 + .25 * (sub4[c] * .5 + .5 * sub5[c])\n",
    "    \n",
    "    submissionMix[c] = pred\n",
    "    \n",
    "submissionMix.to_csv('submissions/final_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
